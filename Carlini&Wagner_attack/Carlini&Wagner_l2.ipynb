{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785a383a-5af5-413f-9330-a23ad35c16ae",
   "metadata": {},
   "source": [
    "# Exemple de l'attaque Carlini & Wagner l2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e437bf86-8d1d-49a1-af4a-4ea3a7b80b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f25db-96e5-4445-8b1d-d2a43c0a74fb",
   "metadata": {},
   "source": [
    "1) Mise en place d'un cnn pour MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "070faa1e-b8c0-47f8-8b7c-a11901178679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Première couche convolutionnelle (1 canal d'entrée, 32 canaux de sortie, noyau 3x3)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # Deuxième couche convolutionnelle (32 canaux d'entrée, 64 canaux de sortie, noyau 3x3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Couches entièrement connectées (Aplatissement en 1D puis 10 classes pour la sortie)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # La taille de l'entrée est 64x7x7 après le pooling\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes pour MNIST (0 à 9)\n",
    "        \n",
    "        # Couches de MaxPooling pour réduire les dimensions spatiales\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Couche de Dropout pour la régularisation (éviter le sur-apprentissage)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Appliquer la première couche convolutionnelle suivie de ReLU et MaxPool\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        # Appliquer la deuxième couche convolutionnelle suivie de ReLU et MaxPool\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        \n",
    "        # Aplatir les données 2D en 1D pour les couches entièrement connectées\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Aplatir en un vecteur de taille 64 * 7 * 7\n",
    "        \n",
    "        # Appliquer la première couche entièrement connectée suivie de ReLU et Dropout\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Appliquer le dropout pour la régularisation\n",
    "        \n",
    "        # Couches de sortie avec 10 classes\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "240a8412-5551-4b31-80d0-f965fec30a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "21849ed6-8a46-4cb0-bcfe-005a2346d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations à appliquer aux images du dataset MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convertir les images en tenseurs PyTorch\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normaliser avec une moyenne et un écart-type de 0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "e488a1bb-81f7-4547-a88a-c9ad77bec372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "02300e55-a141-4c06-9578-e9e5d8fde0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les DataLoader pour l'entraînement et les tests\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "8d3bed4c-6ee5-4911-8b09-8401efada547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modèle, la fonction de perte et l'optimiseur\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Pour la classification multi-classes\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "cf33cc0f-26b0-4893-aeb1-f6045b888187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque [1/1], Perte: 0.1818, Précision: 94.44%\n"
     ]
    }
   ],
   "source": [
    "# Boucle d'entraînement\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mettre le modèle en mode entraînement\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Réinitialiser les gradients avant chaque étape\n",
    "        \n",
    "        # Passage avant (forward pass)\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calcul de la perte\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Passage arrière (backward pass) et optimisation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calcul de la précision\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    # Afficher les statistiques pour chaque époque\n",
    "    print(f\"Époque [{epoch+1}/{num_epochs}], Perte: {running_loss/len(train_loader):.4f}, Précision: {100 * correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0342e-b88d-4330-9f64-13a023c04e64",
   "metadata": {},
   "source": [
    "2) Création de l'attaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "779817c7-75f9-4aaa-ac37-df05ff14eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_attack(model, x, y, gamma=1e-3, c_init=1e-2, c_upper=50, b_steps=100, kappa=0.1, lr=1e-3, max_iter=1000):\n",
    "    # Normalisation de l'entrée\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = torch.atanh((2 * x - 1) * gamma)  # Transformation arctanh\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Initialisation des paramètres de recherche binaire\n",
    "    c_lower, c, c_double = 0, c_init, True\n",
    "    l_min = float('inf')\n",
    "    \n",
    "    # Boucle de recherche binaire\n",
    "    while b_steps > 0 and c < c_upper:\n",
    "        x_new = minimize_objective(model, x_adv, x, c, y, kappa, lr, max_iter)  # Minimisation de l'objectif\n",
    "        \n",
    "        # Vérification si l'attaque réussit\n",
    "        with torch.no_grad():\n",
    "            pred = model(x_new).argmax(dim=1)\n",
    "        attack_success = (pred == y).all()\n",
    "        \n",
    "        if attack_success and torch.norm(x_new - x, p=2).item() < l_min:\n",
    "            print(\"success\")\n",
    "            l_min = torch.norm(x_new - x, p=2).item()\n",
    "            x_adv = x_new.clone()\n",
    "        \n",
    "        # Mise à jour du coefficient c\n",
    "        c, c_double = update_c(c, c_double, attack_success)\n",
    "        b_steps -= 1\n",
    "    \n",
    "    # Transformation inverse\n",
    "    x_adv = (torch.tanh(x_adv) / gamma + 1) / 2\n",
    "    x_adv = torch.clamp(x_adv * (x_max - x_min) + x_min, 0, 1)  # S'assurer que x_adv reste dans [0,1]\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "# Fonction de perte pour forcer la classe cible\n",
    "def loss_function(x_adv, x, c, y, kappa):\n",
    "    z = model(x_adv)\n",
    "    y_pred = z.gather(1, y.view(-1, 1)).squeeze(1)  # Score de la classe cible\n",
    "    z_other = torch.max(z + (y.view(-1, 1) == torch.arange(z.shape[1], device=x.device)).float() * -1e4, dim=1)[0]  # Max des autres classes\n",
    "    loss = torch.max(z_other - y_pred + kappa, torch.tensor(0.0, device=x.device)).mean()  # Force y comme prédiction\n",
    "    return loss + c * torch.norm(x_adv - x, p=2) ** 2  # Régularisation L2\n",
    "        \n",
    "# Fonction de minimisation avec Adam\n",
    "def minimize_objective(model, x_adv, x, c, y, kappa, lr=1e-3, max_iter=500):\n",
    "    optimizer = torch.optim.Adam([x_adv], lr=lr)\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(x_adv, x, c, y, kappa)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        x_adv.data = torch.clamp(x, -1, 1)  # Contrainte pour éviter des valeurs extrêmes\n",
    "    return x_adv.detach()\n",
    "\n",
    "# Mise à jour progressive de c\n",
    "def update_c(c, c_double, success):\n",
    "    if success:\n",
    "        c /= 2  # Réduction si l'attaque réussit\n",
    "    else:\n",
    "        c *= 2  # Augmentation si l'attaque échoue\n",
    "    return c, c_double\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d82ea50-5f06-44d2-8b67-13e2b7e7fc5f",
   "metadata": {},
   "source": [
    "3) Execution de l'attaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "eba23007-7bb7-4dc4-81f6-67bc03de94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécution de l'attaque sur une seule image\n",
    "image, label = next(iter(test_loader))\n",
    "image, label = image.to(device), label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "b5b183a5-46c5-4918-95ed-cb61efcd892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération de l'exemple adversarial \n",
    "target_label = 9\n",
    "adv_image = cw_attack(model, image, torch.tensor([target_label]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "6dc29b4c-ee16-4cba-bd7a-2f524b7aedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "4bdc2ad3-1648-4305-a618-c8eaa7be92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'affichage des résultats\n",
    "def imshow(img, title=\"\"):\n",
    "    img = img.cpu().detach().numpy().squeeze()\n",
    "    img = (img - img.min()) / (img.max() - img.min())  # Normalisation pour l'affichage\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "2a48ab89-0bd9-49b1-9d9d-59e1247adcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction initiale : 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction après attaque : 7\n",
      "Probabilités par classe : [[3.3696906e-05 2.8772987e-04 3.7964359e-03 3.4129054e-03 4.1429248e-05\n",
      "  1.0354547e-05 1.8091919e-07 9.9166334e-01 1.3877836e-04 6.1513344e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Afficher l'image originale et l'image attaquée\n",
    "imshow(image, title=f\"Original: {label.item()}\")\n",
    "pred = model(image).argmax(dim=1).item()\n",
    "print(f\"Prédiction initiale : {pred}\")\n",
    "\n",
    "imshow(adv_image, title=\"Adversarial Image\")\n",
    "pred_adv = model(adv_image).argmax(dim=1).item()\n",
    "print(f\"Prédiction après attaque : {pred_adv}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(adv_image)  # Obtenir les logits\n",
    "    probs = F.softmax(logits, dim=1)  # Convertir en probabilités\n",
    "    print(\"Probabilités par classe :\", probs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dc594-ee59-4cce-8fe1-2e9f838b3159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
